{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e012798-3632-4107-8d5a-5f47e7671a9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This notebook is an example: create a copy before running it or you will get merge conflicts!\n",
    "\n",
    "This notebook will walk you through the process of normalizing your image data. Before running through the notebook, make sure you've completed section 3 of `1_set_up_toffy.ipynb`, and that your data has already been compensated with rosetta using `4_compensate_image_data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9751084-7855-4005-b152-55895ff40823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage.io as io # new\n",
    "\n",
    "from toffy import normalize\n",
    "from ark.utils.io_utils import list_files, list_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe49e0b-34c2-4f86-b786-403c24b2f678",
   "metadata": {},
   "source": [
    "### You'll first need to specify the location of the relevant files to enable image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48127b8-84da-4763-9c44-01a5bde4c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First specify the name of the run that you'll be normalizing\n",
    "\n",
    "# Then provide the path to your panel\n",
    "panel_path = 'I:\\\\20220518_TONIC_panel_file.csv'\n",
    "panel = pd.read_csv(panel_path)\n",
    "\n",
    "# These paths should point to the folders containing each step of the processing pipeline\n",
    "bin_base_dir = 'I:\\\\run_files'\n",
    "rosetta_base_dir = 'I:\\\\rosetta'\n",
    "normalized_base_dir = 'I:\\\\normalized'\n",
    "mph_base_dir = bin_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e94eb1c-4c55-4c37-99bf-36b9402337a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "moly_base_dir = 'I:\\\\moly_run_fovs'\n",
    "runs = list_folders(rosetta_base_dir)\n",
    "for run in runs[2:]:\n",
    "    run_dir = os.path.join(bin_base_dir, run)\n",
    "    new_dir = os.path.join(moly_base_dir, run)\n",
    "    os.makedirs(new_dir)\n",
    "    moly_fovs = json_utils.list_moly_fovs(run_dir)\n",
    "    for fov in moly_fovs:\n",
    "        files = list_files(run_dir, fov)\n",
    "        for file in files:\n",
    "            shutil.move(os.path.join(run_dir, file), \n",
    "                            os.path.join(new_dir, file))\n",
    "        \n",
    "        shutil.rmtree(os.path.join(rosetta_base_dir, run, fov))\n",
    "        shutil.rmtree(os.path.join('I:\\\\extracted', run, fov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dabb9a-d67d-457e-b5f2-e234e8803c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-17_TONIC_TMA3_run2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc7a0e6-141b-4032-887f-ebbed0a4f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_name in run_names[3:]:\n",
    "    run_dir = os.path.join(bin_base_dir, run_name)\n",
    "    previous_pulses = list_files(run_dir, 'pulse')\n",
    "    for file in previous_pulses:\n",
    "        os.remove(os.path.join(run_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c4a6bc-a2ce-4d68-b499-bfd244d6a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-02-21_TONIC_TMA11_run2',\n",
       " '2022-02-23_TONIC_TMA12_run1',\n",
       " '2022-02-24_TONIC_TMA12_run2',\n",
       " '2022-02-25_TONIC_TMA12_run3',\n",
       " '2022-02-26_TONIC_TMA13',\n",
       " '2022-02-26_TONIC_TMA13_restart',\n",
       " '2022-02-28_TONIC_TMA13_run2',\n",
       " '2022-03-01_TONIC_TMA14_run1',\n",
       " '2022-03-02_TONIC_TMA14_run2',\n",
       " '2022-03-03_TONIC_TMA15_run1',\n",
       " '2022-03-04_TONIC_TMA15_run2',\n",
       " '2022-03-05_TONIC_TMA15_run3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names = list_folders(rosetta_base_dir)\n",
    "run_names[18:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692ee45-47d4-4df6-b553-6b6c0068af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tma14_run1_refit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62142cdc-fb78-4c21-8cb2-77b3fb60d399",
   "metadata": {},
   "source": [
    "### Then, we'll loop over each FOV, generating the necessary normalization files if they weren't already created, then normalizing the images, and finally saving them to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe67691-1676-4c3a-93fc-491e3abd6a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing run 2022-03-01_TONIC_TMA14_run1a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pathology\\toffy\\templates\\..\\toffy\\normalize.py:193: UserWarning: Removing previously generated combined pulse_heights file in I:\\run_files\\2022-03-01_TONIC_TMA14_run1a\n",
      "  warnings.warn('Removing previously generated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing run 2022-03-01_TONIC_TMA14_run1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pathology\\toffy\\templates\\..\\toffy\\normalize.py:193: UserWarning: Removing previously generated combined pulse_heights file in I:\\run_files\\2022-03-01_TONIC_TMA14_run1b\n",
      "  warnings.warn('Removing previously generated '\n"
     ]
    }
   ],
   "source": [
    "run_names = list_folders(rosetta_base_dir)\n",
    "#for run_name in run_names[18:30]:\n",
    "for run_name in ['2022-03-01_TONIC_TMA14_run1a', '2022-03-01_TONIC_TMA14_run1b']:\n",
    "    print(\"analyzing run {}\".format(run_name))\n",
    "    # specify sub-folder for rosetta images\n",
    "    img_sub_folder = 'normalized'\n",
    "\n",
    "    # create directory to hold normalized images\n",
    "    normalized_run_dir = os.path.join(normalized_base_dir, run_name)\n",
    "    if not os.path.exists(normalized_run_dir):\n",
    "        os.makedirs(normalized_run_dir)\n",
    "\n",
    "    # create directory to hold associated processing files\n",
    "    mph_run_dir = os.path.join(mph_base_dir, run_name)\n",
    "    if not os.path.exists(mph_run_dir):\n",
    "        os.makedirs(mph_run_dir)\n",
    "\n",
    "    # get all FOVs\n",
    "    fovs = list_folders(os.path.join(rosetta_base_dir, run_name), 'fov')\n",
    "\n",
    "    # loop over each FOV\n",
    "    for fov in fovs:\n",
    "        # generate mph values\n",
    "        mph_file_path = os.path.join(mph_run_dir, fov + '_pulse_heights.csv')\n",
    "        if not os.path.exists(mph_file_path):\n",
    "            normalize.write_mph_per_mass(base_dir=os.path.join(bin_base_dir, run_name), output_dir=mph_run_dir, \n",
    "                                         fov=fov, masses=panel['Mass'].values, start_offset=0.3, stop_offset=0)\n",
    "        \n",
    "    normalize.normalize_image_data(img_dir=os.path.join(rosetta_base_dir, run_name), norm_dir=normalized_run_dir, pulse_height_dir=mph_run_dir,\n",
    "                               panel_info=panel, img_sub_folder=img_sub_folder, mass_obj_func='poly_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0096ea-491a-45c3-adb8-6db7ffc06a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pathology\\toffy\\templates\\..\\toffy\\normalize.py:193: UserWarning: Removing previously generated combined pulse_heights file in I:\\run_files\\2022-03-01_TONIC_TMA14_run1b\n",
      "  warnings.warn('Removing previously generated '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>fov</th>\n",
       "      <th>pulse_height</th>\n",
       "      <th>pulse_height_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>fov-16-scan-1</td>\n",
       "      <td>4943</td>\n",
       "      <td>4949.369483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>157</td>\n",
       "      <td>fov-16-scan-1</td>\n",
       "      <td>3880</td>\n",
       "      <td>4104.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>158</td>\n",
       "      <td>fov-16-scan-1</td>\n",
       "      <td>4301</td>\n",
       "      <td>4606.614935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>159</td>\n",
       "      <td>fov-16-scan-1</td>\n",
       "      <td>4248</td>\n",
       "      <td>4325.531169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>160</td>\n",
       "      <td>fov-16-scan-1</td>\n",
       "      <td>4019</td>\n",
       "      <td>4354.380519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>149</td>\n",
       "      <td>fov-35-scan-1</td>\n",
       "      <td>2443</td>\n",
       "      <td>2511.222078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>150</td>\n",
       "      <td>fov-35-scan-1</td>\n",
       "      <td>2329</td>\n",
       "      <td>2420.201948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>151</td>\n",
       "      <td>fov-35-scan-1</td>\n",
       "      <td>2419</td>\n",
       "      <td>2624.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>153</td>\n",
       "      <td>fov-35-scan-1</td>\n",
       "      <td>2325</td>\n",
       "      <td>2454.171426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>197</td>\n",
       "      <td>fov-35-scan-1</td>\n",
       "      <td>2490</td>\n",
       "      <td>2353.027273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>940 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mass            fov  pulse_height  pulse_height_fit\n",
       "0      39  fov-16-scan-1          4943       4949.369483\n",
       "26    157  fov-16-scan-1          3880       4104.371429\n",
       "27    158  fov-16-scan-1          4301       4606.614935\n",
       "28    159  fov-16-scan-1          4248       4325.531169\n",
       "29    160  fov-16-scan-1          4019       4354.380519\n",
       "..    ...            ...           ...               ...\n",
       "911   149  fov-35-scan-1          2443       2511.222078\n",
       "912   150  fov-35-scan-1          2329       2420.201948\n",
       "913   151  fov-35-scan-1          2419       2624.613636\n",
       "915   153  fov-35-scan-1          2325       2454.171426\n",
       "939   197  fov-35-scan-1          2490       2353.027273\n",
       "\n",
       "[940 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = '2022-03-01_TONIC_TMA14_run1b'\n",
    "normalize.create_fitted_pulse_heights_file(pulse_height_dir=os.path.join(bin_base_dir, run_name), panel_info=panel, \n",
    "                                           norm_dir=os.path.join(normalized_base_dir, run_name), mass_obj_func='poly_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a32e612-e31b-4f05-bb98-dac83195fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-03-13_TONIC_TMA18_run1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893e7f82-96e9-471b-b1ac-4e36e6e272b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stitched image of before and after\n",
    "import skimage.io as io\n",
    "import natsort as ns\n",
    "from ark.utils import data_utils, load_utils, io_utils\n",
    "import numpy as np\n",
    "\n",
    "normalized=True\n",
    "unnormalized=False\n",
    "\n",
    "# problematic runs to check\n",
    "\n",
    "# bad curve fit: 2022-03-01_TONIC_TMA14_run1\n",
    "run_name = '2022-01-14_TONIC_TMA2_run1'\n",
    "#run_name = '2022-03-13_TONIC_TMA18_run1'\n",
    "\n",
    "normalized_run_dir = os.path.join(normalized_base_dir, run_name)\n",
    "unnormalized_run_dir = os.path.join(rosetta_base_dir, run_name)\n",
    "\n",
    "folders = io_utils.list_folders(normalized_run_dir, 'fov-')\n",
    "folders = ns.natsorted(folders)\n",
    "\n",
    "if normalized:\n",
    "    # get all channels\n",
    "    channels = load_utils.load_imgs_from_tree(unnormalized_run_dir,\n",
    "                                                fovs=folders[:1],\n",
    "                                                img_sub_folder='normalized', \n",
    "                                               dtype='float32').channels.values\n",
    "\n",
    "    # load and stitch normalized data\n",
    "    stitch_dir = os.path.join(normalized_run_dir, 'stitched_images_normalized')\n",
    "    if not os.path.exists(stitch_dir):\n",
    "        os.makedirs(stitch_dir)\n",
    "\n",
    "    for chan in channels[1:]:\n",
    "        img_data = load_utils.load_imgs_from_tree(normalized_run_dir,\n",
    "                                                fovs=folders,\n",
    "                                                img_sub_folder='', \n",
    "                                               dtype='float32',\n",
    "                                                 channels=[chan], \n",
    "                                                 max_image_size=2048)\n",
    "\n",
    "        stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "        # save normalized data\n",
    "        current_img = stitched.loc['stitched_image', :, :, chan].values\n",
    "        io.imsave(os.path.join(stitch_dir, chan + '.tiff'), current_img.astype('float32'), check_contrast=False)\n",
    "\n",
    "\n",
    "if unnormalized:\n",
    "\n",
    "    # load and stitch unnormalized data\n",
    "    unnormalized_run_dir = os.path.join(rosetta_base_dir, run_name)\n",
    "\n",
    "    stitch_dir = os.path.join(normalized_run_dir, 'stitched_images_unnormalized')\n",
    "    if not os.path.exists(stitch_dir):\n",
    "        os.makedirs(stitch_dir)\n",
    "\n",
    "    for chan in channels:\n",
    "        img_data = load_utils.load_imgs_from_tree(unnormalized_run_dir,\n",
    "                                                fovs=folders,\n",
    "                                                img_sub_folder='normalized', \n",
    "                                               dtype='float32',\n",
    "                                                 channels=[chan],\n",
    "                                                 max_image_size=2048)\n",
    "\n",
    "        stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "        # save normalized data\n",
    "        current_img = stitched.loc['stitched_image', :, :, chan].values\n",
    "        io.imsave(os.path.join(stitch_dir, chan + '.tiff'), current_img.astype('float32'), check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0cfdeff-617f-4595-a596-4883513257b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD11c'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = io.imread(os.path.join(normalized_run_dir, 'fov-1-scan-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "719e550b-824e-4517-912c-2c70dc24a0c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Integer overflow from loading TIF image, try a larger dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_imgs_from_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_run_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mfovs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m39\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mimg_sub_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mmax_image_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\toffy_env\\lib\\site-packages\\ark\\utils\\load_utils.py:189\u001b[0m, in \u001b[0;36mload_imgs_from_tree\u001b[1;34m(data_dir, img_sub_folder, fovs, channels, dtype, max_image_size)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# check to make sure that dtype wasn't too small for range of data\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(img_data) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteger overflow from loading TIF image, try a larger dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m row_coords, col_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(img_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mrange\u001b[39m(img_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# remove .tif or .tiff from image name\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Integer overflow from loading TIF image, try a larger dtype"
     ]
    }
   ],
   "source": [
    "img_data = load_utils.load_imgs_from_tree(normalized_run_dir,\n",
    "                                                    fovs=folders[38:39],\n",
    "                                                    img_sub_folder='', \n",
    "                                                   dtype='float32',\n",
    "                                                     channels=[chan], \n",
    "                                                     max_image_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd4e6c5e-fa0f-48ad-845e-caae05508fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fov-44-scan-1'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08694a70-2aa3-4d5b-9616-e604342ae57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_heights = pd.read_csv(os.path.join(mph_base_dir, run_name + '_small_window', 'pulse_heights_combined.csv'))\n",
    "masses = np.unique(panel['Mass'])\n",
    "for i in range(1, 10):\n",
    "        old_name = 'fov-{}-scan-1'.format(i)\n",
    "        new_name = 'fov-0{}-scan-1'.format(i)\n",
    "        pulse_heights = pulse_heights.replace(old_name, new_name)\n",
    "\n",
    "for mass in masses[:1]:\n",
    "    mass = 175\n",
    "    pulse_heights = pulse_heights.sort_values('fov')\n",
    "    fovs = np.unique(pulse_heights['fov'])\n",
    "    mo_fovs = [fov.split('-scan')[0] for fov in fovs if 'scan-2' in fov]\n",
    "    complete_mo_fovs = []\n",
    "    for fov in mo_fovs:\n",
    "        complete_mo_fovs.append(fov + '-scan-1')\n",
    "        complete_mo_fovs.append(fov + '-scan-2')\n",
    "        complete_mo_fovs.append(fov + '-scan-3')\n",
    "    fovs = [fov for fov in fovs if fov not in complete_mo_fovs]\n",
    "    pulse_heights = pulse_heights.loc[np.isin(pulse_heights['fov'], fovs), :]\n",
    "\n",
    "    y = pulse_heights.loc[pulse_heights['mass'] == mass, 'pulse_height'].values\n",
    "    x = np.linspace(0, len(y) - 1, len(y))\n",
    "\n",
    "\n",
    "    def reg_func(_x, _y):\n",
    "        return np.polyval(np.polyfit(_x, _y, 2), np.linspace(0, len(x), len(x)))\n",
    "\n",
    "\n",
    "    from seaborn import algorithms as algo\n",
    "    from seaborn.utils import ci\n",
    "    yhat_boots = algo.bootstrap(pd.Series(x), pd.Series(y), func=reg_func,\n",
    "                                n_boot=1000, units=None)\n",
    "    err_bands = ci(yhat_boots, 95, axis=0)\n",
    "\n",
    "    top_band = err_bands[1]\n",
    "    outlier_fovs = []\n",
    "    for idx, val in enumerate(y):\n",
    "        if val > top_band[idx]:\n",
    "            outlier_fovs.append(fovs[idx])\n",
    "\n",
    "    outlier_fovs = [fov.replace('-0', '-') for fov in outlier_fovs]\n",
    "    \n",
    "    # create directory to hold stiched images\n",
    "    out_dir = os.path.join(normalized_base_dir, run_name, 'outlier_fovs_{}'.format(mass))\n",
    "    os.makedirs(out_dir)\n",
    "    channel_name = panel.loc[panel['Mass'] == mass, 'Target'].values[0]\n",
    "    \n",
    "    img_data = load_utils.load_imgs_from_tree(os.path.join(rosetta_base_dir, run_name),\n",
    "                                            img_sub_folder='normalized', \n",
    "                                            dtype='float32',\n",
    "                                              fovs=outlier_fovs,\n",
    "                                             channels=[channel_name],\n",
    "                                             max_image_size=2048)\n",
    "\n",
    "    stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "    # save normalized data\n",
    "    current_img = stitched.loc['stitched_image', :, :, channel_name].values\n",
    "    io.imsave(os.path.join(out_dir, channel_name + '.tiff'), current_img, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14082e50-978c-424f-88ca-f43e9a2251e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fov-3-scan-1',\n",
       " 'fov-12-scan-1',\n",
       " 'fov-13-scan-1',\n",
       " 'fov-16-scan-1',\n",
       " 'fov-18-scan-1',\n",
       " 'fov-22-scan-1',\n",
       " 'fov-30-scan-1',\n",
       " 'fov-34-scan-1',\n",
       " 'fov-38-scan-1',\n",
       " 'fov-45-scan-1',\n",
       " 'fov-51-scan-1',\n",
       " 'fov-54-scan-1',\n",
       " 'fov-55-scan-1']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_fovs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "157f10ae-e8b3-42b9-a4d1-af83584fb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fov-50-scan-1',\n",
       " 'fov-51-scan-1',\n",
       " 'fov-52-scan-1',\n",
       " 'fov-54-scan-1',\n",
       " 'fov-55-scan-1']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fovs[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d9b021-c96a-4979-a1dd-73371a35e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots\n",
    "import os\n",
    "import pandas as pd\n",
    "from ark.utils import io_utils\n",
    "\n",
    "run_names = ['2022-01-14_TONIC_TMA2_run1', '2022-01-21_TONIC_TMA5', '2022-01-26_TONIC_TMA9', '2022-02-26_TONIC_TMA13',\n",
    "            '2022-03-02_TONIC_TMA14_run2', '2022-03-14_TONIC_TMA18_run3', '2022-04-05_TONIC_TMA20_run1', '2022-04-10_TONIC_TMA22_run1']\n",
    "\n",
    "for run in run_names:\n",
    "    run_dir = os.path.join(mph_base_dir, run + '_small_window')\n",
    "    files = io_utils.list_files(run_dir, '_pulse_heights')\n",
    "\n",
    "    metrics = []\n",
    "    for file in files:\n",
    "        metrics.append(pd.read_csv(os.path.join(run_dir, file)))\n",
    "\n",
    "    metrics = pd.concat(metrics)\n",
    "\n",
    "    metrics.to_csv(os.path.join(run_dir, 'pulse_heights_combined.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38865fa9-22ad-40b8-a783-9005420f90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort as ns\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for run in run_names[:1]:\n",
    "    run_dir = os.path.join(mph_base_dir, run + '_small_window')\n",
    "    pulse_heights = pd.read_csv(os.path.join(run_dir, 'pulse_heights_combined.csv'))\n",
    "    fovs = ns.natsorted(pulse_heights['fov'].unique())\n",
    "    \n",
    "    mo_fovs = [fov.split('-scan')[0] for fov in fovs if 'scan-2' in fov]\n",
    "    complete_mo_fovs = []\n",
    "    for fov in mo_fovs:\n",
    "        complete_mo_fovs.append(fov + '-scan-1')\n",
    "        complete_mo_fovs.append(fov + '-scan-2')\n",
    "        complete_mo_fovs.append(fov + '-scan-3')\n",
    "    fovs = [fov for fov in fovs if fov not in complete_mo_fovs]\n",
    "    pulse_heights = pulse_heights.loc[np.isin(pulse_heights['fov'], fovs), :]\n",
    "    \n",
    "    pulse_heights['fov'] = pd.Categorical(pulse_heights['fov'], ordered=True,\n",
    "                                               categories=ns.natsorted(pulse_heights['fov'].unique()))\n",
    "    pulse_heights = pulse_heights.sort_values('fov')\n",
    "\n",
    "    # add numerical column for fovs to enable easier plotting by acq order\n",
    "    fov_names = pulse_heights['fov'].values.tolist()\n",
    "    fov_nums = [float(fov_name.split('-')[1]) for fov_name in fov_names]\n",
    "    pulse_heights['acq_order'] = fov_nums\n",
    "\n",
    "    for mass in np.unique(pulse_heights['mass'].values):\n",
    "\n",
    "        plot_data = pulse_heights.loc[pulse_heights['mass'] == mass]\n",
    "\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        # g = sns.FacetGrid(data=plot_data, x='acq_order', y='pulse_height')\n",
    "        sns.regplot(x='acq_order', y='pulse_height', data=plot_data, order=2)\n",
    "\n",
    "        plot_dir = os.path.join(run_dir, 'mph_v_acq_per_mass')\n",
    "        if not os.path.exists(plot_dir):\n",
    "            os.makedirs(plot_dir)\n",
    "        plt.savefig(os.path.join(plot_dir, str(mass) + '_mph_vs_acq.pdf'), bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43dbe77-86fa-44df-acb6-ec0c6f1b6415",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'standardTarget'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m jp:\n\u001b[0;32m      3\u001b[0m     json_file \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(jp)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mjson_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstandardTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'standardTarget'"
     ]
    }
   ],
   "source": [
    "\n",
    "json_path = os.path.join(bin_base_dir, run_name, 'fov-18-scan-1.json')\n",
    "with open(json_path, 'r') as jp:\n",
    "    json_file = json.load(jp)\n",
    "\n",
    "json_file['standardTarget']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel clustering notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "import"
    ]
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import feather\n",
    "import json\n",
    "from matplotlib import rc_file_defaults\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from ark.analysis import visualize\n",
    "from ark.phenotyping import som_utils\n",
    "from ark.utils import data_utils, io_utils, load_utils, plot_utils\n",
    "from ark.utils.metacluster_remap_gui import MetaClusterData, MetaClusterGui, metaclusterdata_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_pixels_short(fovs, channels, base_dir, data_dir='pixel_mat_data',\n",
    "                   norm_vals_name='post_rowsum_chan_norm.feather',\n",
    "                   weights_name='pixel_weights.feather',\n",
    "                   pc_chan_avg_som_cluster_name='pixel_channel_avg_som_cluster.csv',\n",
    "                   batch_size=5):\n",
    "    \"\"\"Uses trained weights to assign cluster labels on full pixel data\n",
    "    Saves data with cluster labels to `cluster_dir`. Computes and saves the average channel\n",
    "    expression across pixel SOM clusters.\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to subset on\n",
    "        channels (list):\n",
    "            The list of channels to subset on\n",
    "        base_dir (str):\n",
    "            The path to the data directory\n",
    "        data_dir (str):\n",
    "            Name of the directory which contains the full preprocessed pixel data\n",
    "        norm_vals_name (str):\n",
    "            The name of the file with the 99.9% normalized values, created by `train_pixel_som`\n",
    "        weights_name (str):\n",
    "            The name of the weights file created by `train_pixel_som`\n",
    "        pc_chan_avg_som_cluster_name (str):\n",
    "            The name of the file to save the average channel expression across all SOM clusters\n",
    "        batch_size (int):\n",
    "            The number of FOVs to process in parallel\n",
    "    \"\"\"\n",
    "\n",
    "    # define the paths to the data\n",
    "    data_path = os.path.join(base_dir, data_dir)\n",
    "    norm_vals_path = os.path.join(base_dir, norm_vals_name)\n",
    "    weights_path = os.path.join(base_dir, weights_name)\n",
    "    output_path = data_path + '_clustered'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # if path to the preprocessed directory does not exist\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError('Pixel data directory %s does not exist in base_dir %s' %\n",
    "                                (data_dir, base_dir))\n",
    "\n",
    "    # if path to the normalized values file does not exist\n",
    "    if not os.path.exists(norm_vals_path):\n",
    "        raise FileNotFoundError('Normalized values file %s does not exist in base_dir %s' %\n",
    "                                (norm_vals_path, base_dir))\n",
    "    \n",
    "\n",
    "    # if path to the weights file does not exist\n",
    "    if not os.path.exists(weights_path):\n",
    "        raise FileNotFoundError('Weights file %s does not exist in base_dir %s' %\n",
    "                                (weights_name, base_dir))\n",
    "\n",
    "    # verify that all provided fovs exist in the folder\n",
    "    # NOTE: remove the channel and pixel normalization files as those are not pixel data\n",
    "    data_files = io_utils.list_files(data_path, substrs='.feather')\n",
    "    misc_utils.verify_in_list(provided_fovs=fovs,\n",
    "                              subsetted_fovs=io_utils.remove_file_extensions(data_files))\n",
    "\n",
    "    weights = feather.read_dataframe(os.path.join(base_dir, weights_name))\n",
    "\n",
    "    # ensure the norm vals columns and the FOV data contain valid indexes\n",
    "    # ignoring metadata columns in the FOV data, the columns need to be in exactly\n",
    "    # the same order across both datasets (normalized values and FOV values)\n",
    "    norm_vals = feather.read_dataframe(os.path.join(base_dir, norm_vals_name))\n",
    "    sample_fov = feather.read_dataframe(os.path.join(base_dir, data_dir, data_files[0]))\n",
    "\n",
    "    # for verification purposes, drop the metadata columns\n",
    "    cols_to_drop = ['fov', 'row_index', 'column_index']\n",
    "    for col in ['segmentation_label', 'pixel_som_cluster',\n",
    "                'pixel_meta_cluster', 'pixel_meta_cluster_rename']:\n",
    "        if col in sample_fov.columns.values:\n",
    "            cols_to_drop.append(col)\n",
    "\n",
    "    sample_fov = sample_fov.drop(\n",
    "        columns=cols_to_drop\n",
    "    )\n",
    "    misc_utils.verify_same_elements(\n",
    "        enforce_order=True,\n",
    "        norm_vals_columns=norm_vals.columns.values,\n",
    "        pixel_data_columns=sample_fov.columns.values\n",
    "    )\n",
    "\n",
    "    # ensure the weights columns are valid indexes\n",
    "    misc_utils.verify_same_elements(\n",
    "        enforce_order=True,\n",
    "        pixel_weights_columns=weights.columns.values,\n",
    "        pixel_data_columns=sample_fov.columns.values\n",
    "    )\n",
    "\n",
    "    # run the trained SOM on the dataset, assigning clusters\n",
    "    process_args = ['Rscript', '/run_pixel_som.R', ','.join(fovs),\n",
    "                    data_path, norm_vals_path, weights_path, str(batch_size), output_path]\n",
    "\n",
    "    process = subprocess.Popen(process_args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "    # continuously poll the process for output/error so it gets displayed in the Jupyter notebook\n",
    "    while True:\n",
    "        # convert from byte string\n",
    "        output = process.stdout.readline().decode('utf-8')\n",
    "\n",
    "        # if the output is nothing and the process is done, break\n",
    "        if process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        raise MemoryError(\n",
    "            \"Process terminated: you likely have a memory-related error. Try increasing \"\n",
    "            \"your Docker memory limit.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_consensus_cluster_short(fovs, channels, base_dir, max_k=20, cap=3,\n",
    "                            data_dir='pixel_mat_data_clustered',\n",
    "                            pc_chan_avg_som_cluster_name='pixel_channel_avg_som_cluster.csv',\n",
    "                            pc_chan_avg_meta_cluster_name='pixel_channel_avg_meta_cluster.csv',\n",
    "                            clust_to_meta_name='pixel_clust_to_meta.feather',\n",
    "                            batch_size=5, seed=42):\n",
    "    \"\"\"Run consensus clustering algorithm on pixel-level summed data across channels\n",
    "    Saves data with consensus cluster labels to `consensus_dir`. Computes and saves the\n",
    "    average channel expression across pixel meta clusters. Assigns meta cluster labels\n",
    "    to the data stored in `pc_chan_avg_som_cluster_name`.\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to subset on\n",
    "        channels (list):\n",
    "            The list of channels to subset on\n",
    "        base_dir (str):\n",
    "            The path to the data directory\n",
    "        max_k (int):\n",
    "            The number of consensus clusters\n",
    "        cap (int):\n",
    "            z-score cap to use when hierarchical clustering\n",
    "        data_dir (str):\n",
    "            Name of the directory which contains the full preprocessed pixel data.\n",
    "            This data should also have the SOM cluster labels appended from `cluster_pixels`.\n",
    "        pc_chan_avg_som_cluster_name (str):\n",
    "            Name of file to save the channel-averaged results across all SOM clusters to\n",
    "        pc_chan_avg_meta_cluster_name (str):\n",
    "            Name of file to save the channel-averaged results across all meta clusters to\n",
    "        clust_to_meta_name (str):\n",
    "            Name of file storing the SOM cluster to meta cluster mapping\n",
    "        batch_size (int):\n",
    "            The number of FOVs to process in parallel\n",
    "        seed (int):\n",
    "            The random seed to set for consensus clustering\n",
    "    \"\"\"\n",
    "\n",
    "    # define the paths to the data\n",
    "    data_path = os.path.join(base_dir, data_dir)\n",
    "    som_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_som_cluster_name)\n",
    "    clust_to_meta_path = os.path.join(base_dir, clust_to_meta_name)\n",
    "    output_path = data_path + '_consensus'\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # if the path to the SOM clustered data doesn't exist\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Data dir %s does not exist in base_dir %s' %\n",
    "            (data_dir, base_dir)\n",
    "        )\n",
    "\n",
    "    # if the path to the average channel expression per SOM cluster doesn't exist\n",
    "    if not os.path.exists(som_cluster_avg_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Channel avg per SOM cluster file %s does not exist in base_dir %s' %\n",
    "            (pc_chan_avg_som_cluster_name, base_dir)\n",
    "        )\n",
    "\n",
    "    # run the consensus clustering process\n",
    "    process_args = ['Rscript', '/pixel_consensus_cluster.R', ','.join(fovs), ','.join(channels),\n",
    "                    str(max_k), str(cap), data_path, som_cluster_avg_path,\n",
    "                    clust_to_meta_path, str(batch_size), str(seed), output_path]\n",
    "\n",
    "    process = subprocess.Popen(process_args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "    # continuously poll the process for output/error so it gets displayed in the Jupyter notebook\n",
    "    while True:\n",
    "        # convert from byte string\n",
    "        output = process.stdout.readline().decode('utf-8')\n",
    "\n",
    "        # if the output is nothing and the process is done, break\n",
    "        if process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        raise MemoryError(\n",
    "            \"Process terminated: you likely have a memory-related error. Try increasing \"\n",
    "            \"your Docker memory limit.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pixel_meta_labels(pixel_data_path, pixel_remapped_dict,\n",
    "                             pixel_renamed_meta_dict, fov):\n",
    "    \"\"\"Helper function to reassign meta cluster names based on remapping scheme to a FOV\n",
    "    Args:\n",
    "        pixel_data_path (str):\n",
    "            The path to the pixel data drectory\n",
    "        pixel_remapped_dict (dict):\n",
    "            The mapping from pixel SOM cluster to pixel meta cluster label (not renamed)\n",
    "        pixel_renamed_meta_dict (dict):\n",
    "            The mapping from pixel meta cluster label to renamed pixel meta cluster name\n",
    "        fov (str):\n",
    "            The name of the FOV to process\n",
    "    \"\"\"\n",
    "\n",
    "    # get the path to the fov\n",
    "    fov_path = os.path.join(pixel_data_path, fov + '.feather')\n",
    "\n",
    "    # read in the fov data with SOM and meta cluster labels\n",
    "    fov_data = feather.read_dataframe(fov_path)\n",
    "\n",
    "    # ensure that no SOM clusters are missing from the mapping\n",
    "    misc_utils.verify_in_list(\n",
    "        fov_som_labels=fov_data['pixel_som_cluster'],\n",
    "        som_labels_in_mapping=list(pixel_remapped_dict.keys())\n",
    "    )\n",
    "\n",
    "    # assign the new meta cluster labels\n",
    "    fov_data['pixel_meta_cluster'] = fov_data['pixel_som_cluster'].map(\n",
    "        pixel_remapped_dict\n",
    "    )\n",
    "\n",
    "    # assign the renamed meta cluster names\n",
    "    fov_data['pixel_meta_cluster_rename'] = fov_data['pixel_meta_cluster'].map(\n",
    "        pixel_renamed_meta_dict\n",
    "    )\n",
    "\n",
    "    # resave the data with the new meta cluster lables\n",
    "    feather.write_dataframe(fov_data, fov_path, compression='uncompressed')\n",
    "\n",
    "\n",
    "def apply_pixel_meta_cluster_remapping(fovs, channels, base_dir,\n",
    "                                       pixel_data_dir,\n",
    "                                       pixel_remapped_name,\n",
    "                                       pc_chan_avg_som_cluster_name,\n",
    "                                       pc_chan_avg_meta_cluster_name,\n",
    "                                       batch_size=5):\n",
    "    \"\"\"Apply the meta cluster remapping to the data in `pixel_consensus_dir`.\n",
    "    Resave the re-mapped consensus data to `pixel_consensus_dir` and re-runs the\n",
    "    average channel expression per pixel meta cluster computation.\n",
    "    Re-maps the pixel SOM clusters to meta clusters in `pc_chan_avg_som_cluster_name`.\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to subset on\n",
    "        channels (list):\n",
    "            The list of channels to subset on\n",
    "        base_dir (str):\n",
    "            The path to the data directories\n",
    "        pixel_data_dir (str):\n",
    "            Name of directory with the full pixel data.\n",
    "            This data should also have the SOM cluster labels appended from `cluster_pixels`\n",
    "            and the meta cluster labels appended from `pixel_consensus_cluster`.\n",
    "        pixel_remapped_name (str):\n",
    "            Name of the file containing the pixel SOM clusters to their remapped meta clusters\n",
    "        pc_chan_avg_som_cluster_name (str):\n",
    "            Name of the file containing the channel-averaged results across all SOM clusters\n",
    "        pc_chan_avg_meta_cluster_name (str):\n",
    "            Name of the file containing the channel-averaged results across all meta clusters\n",
    "        batch_size (int):\n",
    "            The number of FOVs to process in parallel\n",
    "    \"\"\"\n",
    "\n",
    "    # define the data paths\n",
    "    pixel_data_path = os.path.join(base_dir, pixel_data_dir)\n",
    "    pixel_remapped_path = os.path.join(base_dir, pixel_remapped_name)\n",
    "    som_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_som_cluster_name)\n",
    "    meta_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_meta_cluster_name)\n",
    "\n",
    "    # file path validation\n",
    "    if not os.path.exists(pixel_data_path):\n",
    "        raise FileNotFoundError('Pixel data dir %s does not exist in base_dir %s' %\n",
    "                                (pixel_data_dir, base_dir))\n",
    "\n",
    "    if not os.path.exists(pixel_remapped_path):\n",
    "        raise FileNotFoundError('Pixel remapping file %s does not exist in base_dir %s' %\n",
    "                                (pixel_remapped_name, base_dir))\n",
    "\n",
    "    if not os.path.exists(som_cluster_avg_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Channel average per SOM cluster file %s does not exist in base_dir %s' %\n",
    "            (pc_chan_avg_meta_cluster_name, base_dir))\n",
    "\n",
    "    if not os.path.exists(meta_cluster_avg_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Channel average per meta cluster file %s does not exist in base_dir %s' %\n",
    "            (pc_chan_avg_meta_cluster_name, base_dir))\n",
    "\n",
    "    # read in the remapping\n",
    "    pixel_remapped_data = pd.read_csv(pixel_remapped_path)\n",
    "\n",
    "    # assert the correct columns are contained\n",
    "    misc_utils.verify_same_elements(\n",
    "        remapped_data_cols=pixel_remapped_data.columns.values,\n",
    "        required_cols=['cluster', 'metacluster', 'mc_name']\n",
    "    )\n",
    "\n",
    "    # rename columns in pixel_remapped_data so it plays better with the existing\n",
    "    # pixel_som_cluster and pixel_meta_cluster\n",
    "    pixel_remapped_data = pixel_remapped_data.rename(\n",
    "        {\n",
    "            'cluster': 'pixel_som_cluster',\n",
    "            'metacluster': 'pixel_meta_cluster',\n",
    "            'mc_name': 'pixel_meta_cluster_rename'\n",
    "        },\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # create the mapping from pixel SOM to pixel meta cluster\n",
    "    pixel_remapped_dict = dict(\n",
    "        pixel_remapped_data[\n",
    "            ['pixel_som_cluster', 'pixel_meta_cluster']\n",
    "        ].values\n",
    "    )\n",
    "\n",
    "    # create the mapping from pixel meta cluster to renamed pixel meta cluster\n",
    "    pixel_renamed_meta_dict = dict(\n",
    "        pixel_remapped_data[\n",
    "            ['pixel_meta_cluster', 'pixel_meta_cluster_rename']\n",
    "        ].drop_duplicates().values\n",
    "    )\n",
    "\n",
    "    # define the partial function to iterate over\n",
    "    fov_data_func = partial(\n",
    "        update_pixel_meta_labels, pixel_data_path,\n",
    "        pixel_remapped_dict, pixel_renamed_meta_dict\n",
    "    )\n",
    "\n",
    "    # define the multiprocessing context\n",
    "    with multiprocessing.get_context('spawn').Pool(batch_size) as fov_data_pool:\n",
    "        # define variable to keep track of number of fovs processed\n",
    "        fovs_processed = 0\n",
    "\n",
    "        # asynchronously generate and save the pixel matrices per FOV\n",
    "        print(\"Using re-mapping scheme to re-label pixel meta clusters\")\n",
    "        for fov_batch in [fovs[i:(i + batch_size)] for i in range(0, len(fovs), batch_size)]:\n",
    "            # NOTE: we don't need a return value since we're just resaving\n",
    "            # and not computing intermediate data frames\n",
    "            fov_data_pool.map(fov_data_func, fov_batch)\n",
    "\n",
    "            # update number of fovs processed\n",
    "            fovs_processed += len(fov_batch)\n",
    "\n",
    "            print(\"Processed %d fovs\" % fovs_processed)\n",
    "\n",
    "    # re-compute average channel expression for each pixel meta cluster\n",
    "    # and the number of pixels per meta cluster, add renamed meta cluster column in\n",
    "    print(\"Re-computing average channel expression across pixel meta clusters\")\n",
    "    pixel_channel_avg_meta_cluster = compute_pixel_cluster_channel_avg(\n",
    "        fovs,\n",
    "        channels,\n",
    "        base_dir,\n",
    "        'pixel_meta_cluster',\n",
    "        pixel_data_dir,\n",
    "        keep_count=True\n",
    "    )\n",
    "    pixel_channel_avg_meta_cluster['pixel_meta_cluster_rename'] = \\\n",
    "        pixel_channel_avg_meta_cluster['pixel_meta_cluster'].map(pixel_renamed_meta_dict)\n",
    "\n",
    "    # re-save the pixel channel average meta cluster table\n",
    "    pixel_channel_avg_meta_cluster.to_csv(meta_cluster_avg_path, index=False)\n",
    "\n",
    "    # re-assign pixel meta cluster labels back to the pixel channel average som cluster table\n",
    "    print(\"Re-assigning meta cluster column in pixel SOM cluster average channel expression table\")\n",
    "    pixel_channel_avg_som_cluster = pd.read_csv(som_cluster_avg_path)\n",
    "\n",
    "    pixel_channel_avg_som_cluster['pixel_meta_cluster'] = \\\n",
    "        pixel_channel_avg_som_cluster['pixel_som_cluster'].map(pixel_remapped_dict)\n",
    "\n",
    "    pixel_channel_avg_som_cluster['pixel_meta_cluster_rename'] = \\\n",
    "        pixel_channel_avg_som_cluster['pixel_meta_cluster'].map(pixel_renamed_meta_dict)\n",
    "\n",
    "    # re-save the pixel channel average som cluster table\n",
    "    pixel_channel_avg_som_cluster.to_csv(som_cluster_avg_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pixel_meta_cluster_remapping_short(fovs, channels, base_dir,\n",
    "                                       pixel_data_dir,\n",
    "                                       pixel_remapped_name,\n",
    "                                       pc_chan_avg_som_cluster_name,\n",
    "                                       pc_chan_avg_meta_cluster_name,\n",
    "                                       batch_size=5):\n",
    "    \"\"\"Apply the meta cluster remapping to the data in `pixel_consensus_dir`.\n",
    "    Resave the re-mapped consensus data to `pixel_consensus_dir` and re-runs the\n",
    "    average channel expression per pixel meta cluster computation.\n",
    "    Re-maps the pixel SOM clusters to meta clusters in `pc_chan_avg_som_cluster_name`.\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to subset on\n",
    "        channels (list):\n",
    "            The list of channels to subset on\n",
    "        base_dir (str):\n",
    "            The path to the data directories\n",
    "        pixel_data_dir (str):\n",
    "            Name of directory with the full pixel data.\n",
    "            This data should also have the SOM cluster labels appended from `cluster_pixels`\n",
    "            and the meta cluster labels appended from `pixel_consensus_cluster`.\n",
    "        pixel_remapped_name (str):\n",
    "            Name of the file containing the pixel SOM clusters to their remapped meta clusters\n",
    "        pc_chan_avg_som_cluster_name (str):\n",
    "            Name of the file containing the channel-averaged results across all SOM clusters\n",
    "        pc_chan_avg_meta_cluster_name (str):\n",
    "            Name of the file containing the channel-averaged results across all meta clusters\n",
    "        batch_size (int):\n",
    "            The number of FOVs to process in parallel\n",
    "    \"\"\"\n",
    "\n",
    "    # define the data paths\n",
    "    pixel_data_path = os.path.join(base_dir, pixel_data_dir)\n",
    "    pixel_remapped_path = os.path.join(base_dir, pixel_remapped_name)\n",
    "    som_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_som_cluster_name)\n",
    "    meta_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_meta_cluster_name)\n",
    "\n",
    "    # file path validation\n",
    "    if not os.path.exists(pixel_data_path):\n",
    "        raise FileNotFoundError('Pixel data dir %s does not exist in base_dir %s' %\n",
    "                                (pixel_data_dir, base_dir))\n",
    "\n",
    "    if not os.path.exists(pixel_remapped_path):\n",
    "        raise FileNotFoundError('Pixel remapping file %s does not exist in base_dir %s' %\n",
    "                                (pixel_remapped_name, base_dir))\n",
    "\n",
    "    if not os.path.exists(som_cluster_avg_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Channel average per SOM cluster file %s does not exist in base_dir %s' %\n",
    "            (pc_chan_avg_meta_cluster_name, base_dir))\n",
    "\n",
    "    if not os.path.exists(meta_cluster_avg_path):\n",
    "        raise FileNotFoundError(\n",
    "            'Channel average per meta cluster file %s does not exist in base_dir %s' %\n",
    "            (pc_chan_avg_meta_cluster_name, base_dir))\n",
    "\n",
    "    # read in the remapping\n",
    "    pixel_remapped_data = pd.read_csv(pixel_remapped_path)\n",
    "\n",
    "    # assert the correct columns are contained\n",
    "    misc_utils.verify_same_elements(\n",
    "        remapped_data_cols=pixel_remapped_data.columns.values,\n",
    "        required_cols=['cluster', 'metacluster', 'mc_name']\n",
    "    )\n",
    "\n",
    "    # rename columns in pixel_remapped_data so it plays better with the existing\n",
    "    # pixel_som_cluster and pixel_meta_cluster\n",
    "    pixel_remapped_data = pixel_remapped_data.rename(\n",
    "        {\n",
    "            'cluster': 'pixel_som_cluster',\n",
    "            'metacluster': 'pixel_meta_cluster',\n",
    "            'mc_name': 'pixel_meta_cluster_rename'\n",
    "        },\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # create the mapping from pixel SOM to pixel meta cluster\n",
    "    pixel_remapped_dict = dict(\n",
    "        pixel_remapped_data[\n",
    "            ['pixel_som_cluster', 'pixel_meta_cluster']\n",
    "        ].values\n",
    "    )\n",
    "\n",
    "    # create the mapping from pixel meta cluster to renamed pixel meta cluster\n",
    "    pixel_renamed_meta_dict = dict(\n",
    "        pixel_remapped_data[\n",
    "            ['pixel_meta_cluster', 'pixel_meta_cluster_rename']\n",
    "        ].drop_duplicates().values\n",
    "    )\n",
    "\n",
    "    # define the partial function to iterate over\n",
    "    fov_data_func = partial(\n",
    "        som_utils.update_pixel_meta_labels, pixel_data_path,\n",
    "        pixel_remapped_dict, pixel_renamed_meta_dict\n",
    "    )\n",
    "\n",
    "    # define the multiprocessing context\n",
    "    with multiprocessing.get_context('spawn').Pool(batch_size) as fov_data_pool:\n",
    "        # define variable to keep track of number of fovs processed\n",
    "        fovs_processed = 0\n",
    "\n",
    "        # asynchronously generate and save the pixel matrices per FOV\n",
    "        print(\"Using re-mapping scheme to re-label pixel meta clusters\")\n",
    "        for fov_batch in [fovs[i:(i + batch_size)] for i in range(0, len(fovs), batch_size)]:\n",
    "            # NOTE: we don't need a return value since we're just resaving\n",
    "            # and not computing intermediate data frames\n",
    "            fov_data_pool.map(fov_data_func, fov_batch)\n",
    "\n",
    "            # update number of fovs processed\n",
    "            fovs_processed += len(fov_batch)\n",
    "\n",
    "            print(\"Processed %d fovs\" % fovs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import multiprocessing\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "import feather\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.stats as stats\n",
    "from skimage.io import imread, imsave\n",
    "import xarray as xr\n",
    "\n",
    "from ark.analysis import visualize\n",
    "import ark.settings as settings\n",
    "from ark.utils import io_utils\n",
    "from ark.utils import load_utils\n",
    "from ark.utils import misc_utils\n",
    "\n",
    "def compute_pixel_cluster_channel_avg(fovs, channels, base_dir, pixel_cluster_col,\n",
    "                                      pixel_data_dir='pixel_mat_data', keep_count=False):\n",
    "    \"\"\"Compute the average channel values across each pixel SOM cluster\n",
    "    Args:\n",
    "        fovs (list):\n",
    "            The list of fovs to subset on\n",
    "        channels (list):\n",
    "            The list of channels to subset on\n",
    "        base_dir (str):\n",
    "            The path to the data directories\n",
    "        pixel_cluster_col (str):\n",
    "            Name of the column to group by\n",
    "        pixel_data_dir (str):\n",
    "            Name of the directory containing the pixel data with cluster labels\n",
    "        keep_count (bool):\n",
    "            Whether to keep the count column when aggregating or not\n",
    "            This should only be set to `True` for visualization purposes\n",
    "    Returns:\n",
    "        pandas.DataFrame:\n",
    "            Contains the average channel values for each pixel SOM/meta cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # verify the pixel cluster col specified is valid\n",
    "    misc_utils.verify_in_list(\n",
    "        provided_cluster_col=[pixel_cluster_col],\n",
    "        valid_cluster_cols=['pixel_som_cluster', 'pixel_meta_cluster']\n",
    "    )\n",
    "\n",
    "    # define the cluster averages DataFrame\n",
    "    cluster_avgs = pd.DataFrame()\n",
    "    bad_fovs = []\n",
    "\n",
    "    for fov in fovs:\n",
    "        # read in the fovs data\n",
    "        try:\n",
    "            fov_pixel_data = feather.read_dataframe(\n",
    "                os.path.join(base_dir, pixel_data_dir, fov + '.feather')\n",
    "            )\n",
    "\n",
    "            # aggregate the sums and counts\n",
    "            sum_by_cluster = fov_pixel_data.groupby(\n",
    "                pixel_cluster_col\n",
    "            )[channels].sum()\n",
    "            count_by_cluster = fov_pixel_data.groupby(\n",
    "                pixel_cluster_col\n",
    "            )[channels].size().to_frame('count')\n",
    "\n",
    "            # merge the results by column\n",
    "            agg_results = pd.merge(\n",
    "                sum_by_cluster, count_by_cluster, left_index=True, right_index=True\n",
    "            ).reset_index()\n",
    "\n",
    "            # concat the results together\n",
    "            cluster_avgs = pd.concat([cluster_avgs, agg_results])\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "            print(fov)\n",
    "            bad_fovs.append(fov)\n",
    "            \n",
    "\n",
    "    # reset the index of cluster_avgs for consistency\n",
    "    cluster_avgs = cluster_avgs.reset_index(drop=True)\n",
    "\n",
    "    # sum the counts and the channel sums\n",
    "    sum_count_totals = cluster_avgs.groupby(\n",
    "        pixel_cluster_col\n",
    "    )[channels + ['count']].sum().reset_index()\n",
    "\n",
    "    # now compute the means using the count column\n",
    "    sum_count_totals[channels] = sum_count_totals[channels].div(sum_count_totals['count'], axis=0)\n",
    "\n",
    "    # convert cluster column to integer type\n",
    "    sum_count_totals[pixel_cluster_col] = sum_count_totals[pixel_cluster_col].astype(int)\n",
    "\n",
    "    # sort cluster col in ascending order\n",
    "    sum_count_totals = sum_count_totals.sort_values(by=pixel_cluster_col)\n",
    "\n",
    "    # drop the count column if specified\n",
    "    if not keep_count:\n",
    "        sum_count_totals = sum_count_totals.drop('count', axis=1)\n",
    "\n",
    "    return sum_count_totals, bad_fovs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0: set file paths and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `base_dir`: the path to all of your imaging data. Should contain a directory for your images, segmentations, and cell table (generated from `Segment_Image_Data.ipynb`). This directory will also store all of the directories/files created during pixel clustering.\n",
    "* `tiff_dir`: the path to the directory containing your imaging data\n",
    "* `img_sub_folder`: if `tiff_dir` contains an additional subfolder structure, override `None` with the appropriate value\n",
    "* `segmentation_dir`: the path to the directory containing your segmentations (generated from `Segment_Image_Data.ipynb`). Set this argument to `None` if you do not have segmentation labels or wish to run pixel clustering without them. However, note that you will not be able to run cell clustering as that process is heavily dependent on them.\n",
    "* `seg_suffix`: the suffix plus the file extension of the segmented images for each FOV. Note that these should be the same for all FOVs and that normally, the value should be `'_feature_0.tif'`. This argument will be ignored if `segmentation_dir` is set to `None`\n",
    "* `MIBItiff`: if the images in `tiff_dir` are mibitiff or not\n",
    "* `mibitiff_suffix` (required if `MIBItiff` is True): the file suffix all mibitiff images contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "file_path"
    ]
   },
   "outputs": [],
   "source": [
    "base_dir = \"../data/external/\"\n",
    "tiff_dir = os.path.join(base_dir, 'image_data/samples')\n",
    "img_sub_folder = None\n",
    "segmentation_dir = os.path.join(base_dir, 'segmentation_data/deepcell_output')\n",
    "seg_suffix = '_feature_0.tif'\n",
    "MIBItiff = False\n",
    "mibitiff_suffix = '-MassCorrected-Filtered.tiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `fovs` (optional): set a specific set of fovs to load, default loads all the fovs in `tiff_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "load_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "if MIBItiff:\n",
    "    fovs = io_utils.list_files(tiff_dir, substrs=MIBItiff_suffix)\n",
    "else:\n",
    "    fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov14\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fovs = ['TONIC_TMA23_R6C1',\n",
    " 'TONIC_TMA15_R11C2',\n",
    " 'TONIC_TMA23_R9C4',\n",
    " 'TONIC_TMA6_R7C4',\n",
    " 'TONIC_TMA23_R6C3',\n",
    " 'TONIC_TMA18_R2C2',\n",
    " 'TONIC_TMA19_R6C6',\n",
    " 'TONIC_TMA18_R9C1',\n",
    " 'TONIC_TMA4_R1C2',\n",
    " 'TONIC_TMA23_R1C2',\n",
    " 'TONIC_TMA10_R4C1',\n",
    " 'TONIC_TMA10_R3C6',\n",
    " 'TONIC_TMA1_R8C1',\n",
    " 'TONIC_TMA6_R3C6',\n",
    " 'TONIC_TMA14_R3C4',\n",
    " 'TONIC_TMA21_R4C1',\n",
    " 'TONIC_TMA13_R5C1',\n",
    " 'TONIC_TMA7_R7C3',\n",
    " 'TONIC_TMA12_R3C4',\n",
    " 'TONIC_TMA6_R5C2',\n",
    " 'TONIC_TMA11_R8C5',\n",
    " 'TONIC_TMA6_R10C4',\n",
    " 'TONIC_TMA16_R6C6',\n",
    " 'TONIC_TMA20_R4C6',\n",
    " 'TONIC_TMA22_R2C4',\n",
    " 'TONIC_TMA9_R4C4',\n",
    " 'TONIC_TMA3_R6C3',\n",
    " 'TONIC_TMA16_R10C6',\n",
    " 'TONIC_TMA3_R1C6',\n",
    " 'TONIC_TMA14_R10C6',\n",
    " 'TONIC_TMA12_R2C1',\n",
    " 'TONIC_TMA10_R9C2',\n",
    " 'TONIC_TMA12_R3C6',\n",
    " 'TONIC_TMA17_R2C4',\n",
    " 'TONIC_TMA2_R11C4',\n",
    " 'TONIC_TMA2_R5C2',\n",
    " 'TONIC_TMA24_R9C1',\n",
    " 'TONIC_TMA3_R8C1',\n",
    " 'TONIC_TMA4_R10C4',\n",
    " 'TONIC_TMA8_R6C5',\n",
    " 'TONIC_TMA4_R7C2',\n",
    " 'TONIC_TMA20_R5C4',\n",
    " 'TONIC_TMA17_R12C2',\n",
    " 'TONIC_TMA10_R7C2',\n",
    " 'TONIC_TMA8_R8C4',\n",
    " 'TONIC_TMA3_R10C3',\n",
    " 'TONIC_TMA23_R6C2',\n",
    " 'TONIC_TMA24_R2C1',\n",
    " 'TONIC_TMA9_R10C5',\n",
    " 'TONIC_TMA8_R11C4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1: Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a prefix to be applied to all data directories/files created by pixel and cell clustering. If the prefix is not set, a default of the datetime at the start of the run is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "pixel_prefix"
    ]
   },
   "outputs": [],
   "source": [
    "# explicitly set pixel_cluster_prefix to override datetime default\n",
    "pixel_cluster_prefix = '20220707_full_cohort'\n",
    "\n",
    "if pixel_cluster_prefix is None:\n",
    "    pixel_cluster_prefix = dt.now().strftime('%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data directories/files will be created for preprocessing with names prefixed by `pixel_cluster_prefix`:\n",
    "\n",
    "* `pixel_output_dir`: the name of the folder to store the pixel clustering directories/files\n",
    "* `preprocessed_dir`: the name of the directory to save the preprocessed pixel data\n",
    "* `subsetted_dir`: the name of the directory to save the subsetted pixel data\n",
    "* `norm_vals_name`: file name to store the values used to normalize each channel on the full preprocessed dataset when assigning pixel SOM cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "dir_set"
    ]
   },
   "outputs": [],
   "source": [
    "# define the base output pixel folder using the specified pixel cluster prefix\n",
    "pixel_output_dir = '%s_pixel_output_dir' % pixel_cluster_prefix\n",
    "if not os.path.exists(os.path.join(base_dir, pixel_output_dir)):\n",
    "    os.mkdir(os.path.join(base_dir, pixel_output_dir))\n",
    "\n",
    "# define the preprocessed pixel data folders\n",
    "pixel_data_dir = os.path.join(pixel_output_dir, '%s_pixel_mat_data' % pixel_cluster_prefix)\n",
    "pixel_subset_dir = os.path.join(pixel_output_dir, '%s_pixel_mat_subset' % pixel_cluster_prefix)\n",
    "norm_vals_name = os.path.join(pixel_output_dir, 'post_rowsum_chan_norm.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain channels, such as membraneous tumor markers, the subcellular localization of the marker isn't important. Instead, what matters is that cells which are positive for the marker show up as positive. In these cases, we have sometimes found it useful to add additional blurring to these markers before clustering. This ensures that more of the pixels within the cell are positive for the marker, instead of only a few pixels at the border, especially for cells which are under-segmented. However, higher blur levels will also cause more of the pixels in neighboring cells to show up as positive. Therefore, this works best when you have other, robust markers (like CD45) which you can use to determine which cells are false positives for the blurred channel. If you have markers in your panel which fit this description, you can add them in the cell below. Then, when specifying the list of markers to include clustering, make sure to add `marker_name_smoothed`, as that is what the tiff will be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ark/utils/load_utils.py:174: UserWarning: The supplied non-float dtype int16 was overwritten to float64, because the loaded images are floats\n",
      "  warnings.warn(f\"The supplied non-float dtype {dtype} was overwritten to {data_dtype}, \"\n"
     ]
    }
   ],
   "source": [
    "# set an optional list of markers for additional blurring\n",
    "blurred_channels = ['ECAD', 'CK17']\n",
    "smooth_vals = 6\n",
    "som_utils.smooth_channels(fovs=fovs, tiff_dir=tiff_dir, img_sub_folder=img_sub_folder, channels=blurred_channels, smooth_vals=smooth_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ark.utils.load_utils import load_imgs_from_tree, load_imgs_from_dir\n",
    "from ark.utils.misc_utils import verify_same_elements\n",
    "import skimage.io as io\n",
    "\n",
    "def filter_with_nuclear_mask(fovs, tiff_dir, segmentation_dir, channel, img_sub_folder=None, exclude=True):\n",
    "    # convert to path-compatible format\n",
    "    if img_sub_folder is None:\n",
    "        img_sub_folder = ''\n",
    "        \n",
    "    \n",
    "    for fov in fovs:\n",
    "        img = load_utils.load_imgs_from_tree(data_dir=tiff_dir, img_sub_folder=img_sub_folder,\n",
    "                                             fovs=[fov], channels=[channel]).values[0, :, :, 0]\n",
    "        seg_img = io.imread(os.path.join(segmentation_dir, fov + '_feature_1.tif'))[0, ...]\n",
    "        \n",
    "        if exclude:\n",
    "            suffix = '_nuc_exclude.tiff'\n",
    "            seg_mask = seg_img > 0\n",
    "        else:\n",
    "            suffix = '_nuc_include.tiff'\n",
    "            seg_mask = seg_img == 0\n",
    "            \n",
    "        img[seg_mask] = 0\n",
    "        io.imsave(os.path.join(tiff_dir, fov, img_sub_folder, channel + suffix), img, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_with_nuclear_mask(fovs=fovs[10:], tiff_dir=tiff_dir, segmentation_dir=segmentation_dir, channel='CD11c')\n",
    "filter_with_nuclear_mask(fovs=fovs, tiff_dir=tiff_dir, segmentation_dir=segmentation_dir, channel='FOXP3', exclude=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_with_nuclear_mask(fovs=fovs, tiff_dir=tiff_dir, segmentation_dir=segmentation_dir, channel='FOXP3', exclude=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following arguments\n",
    "\n",
    "* `channels`: set a subset to run pixel clustering over\n",
    "* `blur_factor`: the sigma to use for the Gaussian filter when running the Gaussian blur. Higher values are more aggressive in smoothing signal.\n",
    "* `subset_proportion`: the fraction of pixels to take from each fov. Sampling is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "channel_set"
    ]
   },
   "outputs": [],
   "source": [
    "channels = [\"CD45\", \"SMA\", \"Vim\", \"FAP\", \"Fibronectin\", \"Collagen1\", \"CK17_smoothed\", \"ECAD_smoothed\", \"ChyTr\",\n",
    "            \"Calprotectin\",  \"CD3\", \"CD4\", \"CD8\",  \"CD11c_nuc_exclude\", \"CD14\",\"CD20\", \"CD31\", \"CD56\",  \"CD68\", \"CD163\", \"HLADR\", \"FOXP3_nuc_include\"]\n",
    "blur_factor = 2\n",
    "subset_proportion = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "During pixel preprocessing, the following is done for each FOV:\n",
    "\n",
    "* Gaussian blur each channel separately\n",
    "* Remove empty pixels\n",
    "* For the remaining pixels, normalize each channel by the sum of all the channels, this creates the full preprocessed dataset\n",
    "* Subset a `subset_proportion` fraction of non-empty, normalized pixels, this creates the subsetted dataset\n",
    "\n",
    "Note: if you get integer overflow errors loading in your data, try changing the `dtype` argument to a larger type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": [
     "gen_pixel_mat"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2 fovs\n"
     ]
    }
   ],
   "source": [
    "# run pixel data preprocessing\n",
    "som_utils.create_pixel_matrix(\n",
    "    redo_fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    tiff_dir,\n",
    "    segmentation_dir,\n",
    "    img_sub_folder=img_sub_folder,\n",
    "    seg_suffix=seg_suffix,\n",
    "    data_dir=pixel_data_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    is_mibitiff=MIBItiff,\n",
    "    blur_factor=blur_factor,\n",
    "    subset_proportion=subset_proportion,\n",
    "    dtype=\"float32\", \n",
    "    pixel_output_dir=pixel_output_dir,\n",
    "    pixel_cluster_prefix=pixel_cluster_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: pixel clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: train pixel SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data directories/files will be created for pixel clustering:\n",
    "\n",
    "* `pixel_weights_name`: file name to place the pixel SOM weights\n",
    "* `pixel_som_to_meta_name`: file name to store the mapping between pixel SOM clusters and pixel meta clusters\n",
    "* `pc_chan_avg_som_cluster_name`: file name to store the average channel expression across all pixel SOM clusters\n",
    "* `pc_chan_avg_meta_cluster_name`: same as above except for pixel meta clusters\n",
    "* `pixel_meta_cluster_remap_name`: for the meta cluster remapping process, the file to store the new SOM to meta mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "pixel_som_path_set"
    ]
   },
   "outputs": [],
   "source": [
    "pixel_weights_name = os.path.join(pixel_output_dir, '%s_pixel_weights.feather' % pixel_cluster_prefix)\n",
    "pixel_som_to_meta_name = os.path.join(pixel_output_dir, '%s_pixel_som_to_meta.feather' % pixel_cluster_prefix)\n",
    "pc_chan_avg_som_cluster_name = os.path.join(pixel_output_dir, '%s_pixel_channel_avg_som_cluster.csv' % pixel_cluster_prefix)\n",
    "pc_chan_avg_meta_cluster_name = os.path.join(pixel_output_dir, '%s_pixel_channel_avg_meta_cluster.csv' % pixel_cluster_prefix)\n",
    "pixel_meta_cluster_remap_name = os.path.join(pixel_output_dir, '%s_pixel_meta_cluster_mapping.csv' % pixel_cluster_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the pixel SOM on the subsetted data. Training is done using the `FlowSOM` algorithm.\n",
    "\n",
    "Note that each channel is normalized by their 99.9% value across the entire subsetted dataset before training. These values get saved to `norm_vals_name`.\n",
    "\n",
    "For a full set of parameters you can customize for `train_pixel_som`, please consult: <a href=https://ark-analysis.readthedocs.io/en/latest/_markdown/ark.phenotyping.html#ark.phenotyping.som_utils.train_pixel_som>pixel training docs</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "train_pixel_som"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some features are not enabled in this build of Arrow. Run `arrow_info()` for more information.\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "timestamp\n",
      "\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "union\n",
      "\n",
      "Thanks for using FlowSOM. From version 2.1.4 on, the scale\n",
      "parameter in the FlowSOM function defaults to FALSE\n",
      "[1] \"Reading the subsetted pixel matrix data\"\n",
      "[1] \"Performing 99.9% normalization\"\n",
      "[1] \"Training the SOM\"\n",
      "[1] \"Save trained weights\"\n"
     ]
    }
   ],
   "source": [
    "# create the pixel-level SOM weights\n",
    "som_utils.train_pixel_som(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    weights_name=pixel_weights_name,\n",
    "    num_passes=1,\n",
    "    xdim=17,\n",
    "    ydim=17\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Assign pixel SOM clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SOM weights learned from `train_pixel_som` to assign pixel clusters to the full preprocessed dataset.\n",
    "\n",
    "Note that each channel is normalized by the respective value stored in `norm_vals_name` (computed in `train_pixel_som`) prior to cluster assignment.\n",
    "\n",
    "This function also computes the average channel expression across all pixel SOM clusters as well as the number of pixels in each pixel SOM cluster (the data placed in `pc_chan_avg_som_cluster_name`). This is needed for pixel consensus clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": [
     "cluster_pixel_mat"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some features are not enabled in this build of Arrow. Run `arrow_info()` for more information.\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "timestamp\n",
      "\n",
      "Loading required package: foreach\n",
      "Loading required package: iterators\n",
      "Loading required package: parallel\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "union\n",
      "\n",
      "Thanks for using FlowSOM. From version 2.1.4 on, the scale\n",
      "parameter in the FlowSOM function defaults to FALSE\n",
      "[1] \"Mapping pixel data to SOM cluster labels\"\n",
      "[1] \"Processed 2 fovs\"\n",
      "[1] \"Done!\"\n"
     ]
    }
   ],
   "source": [
    "# use pixel SOM weights to assign pixel clusters\n",
    "cluster_pixels_short(\n",
    "    redo_fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    data_dir=pixel_data_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    weights_name=pixel_weights_name,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lz4 compressed input contains more than one frame\n",
      "TONIC_TMA15_R2C6\n"
     ]
    }
   ],
   "source": [
    "pixel_channel_avg_som_cluster, bad_fovs_cluster = compute_pixel_cluster_channel_avg(\n",
    "        fovs,\n",
    "        channels,\n",
    "        base_dir,\n",
    "        'pixel_som_cluster',\n",
    "        pixel_data_dir + '_clustered',\n",
    "        keep_count=True\n",
    "    )\n",
    "\n",
    "# save pixel_channel_avg_som_cluster\n",
    "pixel_channel_avg_som_cluster.to_csv(\n",
    "    os.path.join(base_dir, pc_chan_avg_som_cluster_name),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo_fovs = ['TONIC_TMA24_R5C2', 'TONIC_TMA15_R2C6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprocess FOVs that fail\n",
    "# TODO: delete before reprocessing\n",
    "if len(bad_fovs_cluster) > 0:\n",
    "    for fov in bad_fovs_cluster:\n",
    "        os.remove(os.path.join(pixel_data_dir, fov + '.feather'))\n",
    "        \n",
    "    som_utils.create_pixel_matrix(\n",
    "        bad_fovs_cluster,\n",
    "        channels,\n",
    "        base_dir,\n",
    "        tiff_dir,\n",
    "        segmentation_dir,\n",
    "        img_sub_folder=img_sub_folder,\n",
    "        seg_suffix=seg_suffix,\n",
    "        data_dir=pixel_data_dir,\n",
    "        subset_dir=pixel_subset_dir,\n",
    "        norm_vals_name=norm_vals_name,\n",
    "        is_mibitiff=MIBItiff,\n",
    "        blur_factor=blur_factor,\n",
    "        subset_proportion=subset_proportion,\n",
    "        dtype=\"float32\", \n",
    "        pixel_output_dir=pixel_output_dir\n",
    "    )\n",
    "\n",
    "    cluster_pixels_short(\n",
    "        bad_fovs_cluster,\n",
    "        channels,\n",
    "        base_dir,\n",
    "        data_dir=pixel_data_dir,\n",
    "        norm_vals_name=norm_vals_name,\n",
    "        weights_name=pixel_weights_name,\n",
    "        pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any of the bad_fovs failed again\n",
    "bad_fovs_cluster_x1 = []\n",
    "for fov in bad_fovs_cluster:\n",
    "    try:\n",
    "        feather_file = feather.read_dataframe(os.path.join(base_dir, pixel_data_dir, fov + '.feather'))\n",
    "    except Exception as inst:\n",
    "        print(fov)\n",
    "        print(inst)\n",
    "        bad_fovs_cluster_x1.append(fov)\n",
    "print(bad_fovs_cluster_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: run pixel consensus clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the SOM cluster labels assigned to the full preprocessed pixel data, assign consensus cluster labels. The consensus clusters are trained on the average channel expression across all pixel SOM clusters (the data stored in `pc_chan_avg_som_cluster_name`). These values are z-scored and capped at the value specified in the `cap` argument prior to training: this helps improve the meta clustering process.\n",
    "\n",
    "After consensus clustering, the following are also computed:\n",
    "\n",
    "* The average channel expression across all pixel meta clusters, and the number of pixels per meta cluster (the data placed in `pc_chan_avg_meta_cluster_name`)\n",
    "* The meta cluster mapping for each pixel SOM cluster in `pc_chan_avg_som_cluster_name` (data is resaved, same data except with an associated meta cluster column)\n",
    "\n",
    "For a full set of parameters you can customize for `pixel_consensus_cluster`, please consult: <a href=https://ark-analysis.readthedocs.io/en/latest/_markdown/ark.phenotyping.html#ark.phenotyping.som_utils.pixel_consensus_cluster>pixel consensus clustering docs</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `max_k`: the number of consensus clusters desired\n",
    "* `cap`: used to clip z-scored values prior to consensus clustering (in the range `[-cap, cap]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "pixel_consensus_cluster"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some features are not enabled in this build of Arrow. Run `arrow_info()` for more information.\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "timestamp\n",
      "\n",
      "Loading required package: foreach\n",
      "Loading required package: iterators\n",
      "Loading required package: parallel\n",
      "[1] \"Reading cluster averaged data\"\n",
      "[1] \"Running consensus clustering\"\n",
      "[1] \"Mapping pixel data to consensus cluster labels\"\n",
      "[1] \"Processed 2 fovs\"\n",
      "[1] \"Writing SOM to meta cluster mapping table\"\n"
     ]
    }
   ],
   "source": [
    "max_k = 30\n",
    "cap = 3\n",
    "\n",
    "# run hierarchical clustering based on pixel SOM cluster assignments\n",
    "pixel_consensus_cluster_short(\n",
    "    redo_fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    max_k=max_k,\n",
    "    cap=cap,\n",
    "    data_dir=pixel_data_dir + '_clustered',\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name=pc_chan_avg_meta_cluster_name,\n",
    "    clust_to_meta_name=pixel_som_to_meta_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average channel expression across pixel meta clusters\n",
      "LZ4 decompress failed: ERROR_GENERIC\n",
      "TONIC_TMA24_R5C2\n",
      "Mapping meta cluster values onto average channel expression across pixel SOM clusters\n"
     ]
    }
   ],
   "source": [
    "## If the above fails\n",
    "clust_to_meta_name=pixel_som_to_meta_name\n",
    "\n",
    "# define the paths to the data\n",
    "data_path = os.path.join(base_dir, pixel_data_dir)\n",
    "som_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_som_cluster_name)\n",
    "clust_to_meta_path = os.path.join(base_dir, clust_to_meta_name)   \n",
    "\n",
    "print(\"Computing average channel expression across pixel meta clusters\")\n",
    "pixel_channel_avg_meta_cluster, bad_fovs_meta = compute_pixel_cluster_channel_avg(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    'pixel_meta_cluster',\n",
    "    pixel_data_dir + '_clustered_consensus',\n",
    "    keep_count=True\n",
    ")\n",
    "\n",
    "# save pixel_channel_avg_meta_cluster\n",
    "pixel_channel_avg_meta_cluster.to_csv(\n",
    "    os.path.join(base_dir, pc_chan_avg_meta_cluster_name),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# read in the clust_to_meta_name file\n",
    "print(\"Mapping meta cluster values onto average channel expression across pixel SOM clusters\")\n",
    "som_to_meta_data = feather.read_dataframe(\n",
    "    os.path.join(base_dir, clust_to_meta_name)\n",
    ").astype(np.int64)\n",
    "\n",
    "# read in the channel-averaged results across all pixel SOM clusters\n",
    "pixel_channel_avg_som_cluster = pd.read_csv(som_cluster_avg_path)\n",
    "\n",
    "# merge metacluster assignments in\n",
    "pixel_channel_avg_som_cluster = pd.merge_asof(\n",
    "    pixel_channel_avg_som_cluster, som_to_meta_data, on='pixel_som_cluster'\n",
    ")\n",
    "\n",
    "# resave channel-averaged results across all pixel SOM clusters with metacluster assignments\n",
    "pixel_channel_avg_som_cluster.to_csv(\n",
    "    som_cluster_avg_path,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_fovs_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1: use the interactive reclustering results to relabel pixel meta clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization shows the z-scored average channel expression per pixel SOM and meta cluster. The heatmaps are faceted by pixel SOM clusters on the left and pixel meta clusters on the right.\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Quickstart\n",
    "- **Select**: Left Click\n",
    "- **Remap**: **New metacluster** button or Right Click\n",
    "- **Edit Metacluster Name**: Textbox at bottom right of the heatmaps.\n",
    "\n",
    "### Selection and Remapping details\n",
    "- To select a SOM cluster, click on its respective position in the **selected** bar. Click on it again to deselect.\n",
    "- To select a meta cluster, click on its corresponding color in the **metacluster** bar. Click on it again to deselect.\n",
    "- To remap the selected clusters, click the **New metacluster** button (alternatively, right click anywhere). Note that remapping an entire metacluster deletes it.\n",
    "- To clear the selected SOM/meta clusters, use the **Clear Selection** button.\n",
    "- **After remapping a meta cluster, make sure to deselect the newly created one to prevent unwanted combinations.**\n",
    "\n",
    "### Other features and notes\n",
    "- You will likely need to zoom out to see the entire visualization. To toggle Zoom, use Ctrl -/Ctrl + on Windows or ⌘ +/⌘ - on Mac.\n",
    "- The bars at the top show the number of pixels in each SOM cluster.\n",
    "- The text box at the bottom right allows you to rename a particular meta cluster. This can be useful as remapping may cause inconsistent numbering.\n",
    "- Adjust the z-score limit using the slider on the bottom left to adjust your dynamic range.\n",
    "- When meta clusters are combined or a meta cluster is renamed, the change is immediately saved to `pixel_meta_cluster_remap_name`.\n",
    "- You won't be able to advance in the notebook until you've clicked `New metacluster` or renamed a meta cluster at least once. If you don't want to make changes, just click `New metacluster` to trigger a save before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The visualization shows the z-scored average channel expression per pixel SOM and meta cluster. The heatmaps are faceted by pixel SOM clusters on the left and pixel meta clusters on the right.\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Quickstart\n",
    "- **Select**: Left Click\n",
    "- **Remap**: **New metacluster** button or Right Click\n",
    "- **Edit Metacluster Name**: Textbox at bottom right of the heatmaps.\n",
    "\n",
    "### Selection and Remapping details\n",
    "- To select a SOM cluster, click on its respective position in the **selected** bar. Click on it again to deselect.\n",
    "- To select a meta cluster, click on its corresponding color in the **metacluster** bar. Click on it again to deselect.\n",
    "- To remap the selected clusters, click the **New metacluster** button (alternatively, right click anywhere). Note that remapping an entire metacluster deletes it.\n",
    "- To clear the selected SOM/meta clusters, use the **Clear Selection** button.\n",
    "- **After remapping a meta cluster, make sure to deselect the newly created one to prevent unwanted combinations.**\n",
    "\n",
    "### Other features and notes\n",
    "- You will likely need to zoom out to see the entire visualization. To toggle Zoom, use Ctrl -/Ctrl + on Windows or ⌘ +/⌘ - on Mac.\n",
    "- The bars at the top show the number of pixels in each SOM cluster.\n",
    "- The text box at the bottom right allows you to rename a particular meta cluster. This can be useful as remapping may cause inconsistent numbering.\n",
    "- Adjust the z-score limit using the slider on the bottom left to adjust your dynamic range.\n",
    "- When meta clusters are combined or a meta cluster is renamed, the change is immediately saved to `pixel_meta_cluster_remap_name`.\n",
    "- You won't be able to advance in the notebook until you've clicked `New metacluster` or renamed a meta cluster at least once. If you don't want to make changes, just click `New metacluster` to trigger a save before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "pixel_interactive"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4327baeed047f9acafc33c3295dfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(HBox(children=(FloatSlider(value=3.0, description='Max Zscore:', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "rc_file_defaults()\n",
    "plt.ion()\n",
    "\n",
    "pixel_mcd = metaclusterdata_from_files(\n",
    "    os.path.join(base_dir, pc_chan_avg_som_cluster_name),\n",
    "    cluster_type='pixel'\n",
    ")\n",
    "pixel_mcd.output_mapping_filename = os.path.join(base_dir, pixel_meta_cluster_remap_name)\n",
    "pixel_mcg = MetaClusterGui(pixel_mcd, width=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relabel the pixel meta clusters using the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pixel_apply_remap"
    ]
   },
   "outputs": [],
   "source": [
    "som_utils.apply_pixel_meta_cluster_remapping(\n",
    "    fovs[1210:],\n",
    "    channels,\n",
    "    base_dir,\n",
    "    pixel_data_dir + '_clustered_consensus',\n",
    "    pixel_meta_cluster_remap_name,\n",
    "    pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name, \n",
    "    pixel_data_dir + '_remapped'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TONIC_TMA19_R2C5',\n",
       " 'TONIC_TMA19_R7C3',\n",
       " 'TONIC_TMA19_R7C6',\n",
       " 'TONIC_TMA19_R9C2',\n",
       " 'TONIC_TMA19_R10C4']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fovs[1210:1215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-computing average channel expression across pixel meta clusters\n",
      "Re-assigning meta cluster column in pixel SOM cluster average channel expression table\n"
     ]
    }
   ],
   "source": [
    "# second half of apply_pixel_meta_cluster_remapping that updates files, since default function doesn't use updated directory\n",
    "\n",
    "from ark.utils import misc_utils\n",
    "pixel_data_path = os.path.join(base_dir, pixel_data_dir)\n",
    "pixel_remapped_path = os.path.join(base_dir, pixel_meta_cluster_remap_name)\n",
    "som_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_som_cluster_name)\n",
    "meta_cluster_avg_path = os.path.join(base_dir, pc_chan_avg_meta_cluster_name)\n",
    "\n",
    "pixel_remapped_data = pd.read_csv(pixel_remapped_path)\n",
    "\n",
    "# assert the correct columns are contained\n",
    "misc_utils.verify_same_elements(\n",
    "    remapped_data_cols=pixel_remapped_data.columns.values,\n",
    "    required_cols=['cluster', 'metacluster', 'mc_name']\n",
    ")\n",
    "\n",
    "# rename columns in pixel_remapped_data so it plays better with the existing\n",
    "# pixel_som_cluster and pixel_meta_cluster\n",
    "pixel_remapped_data = pixel_remapped_data.rename(\n",
    "    {\n",
    "        'cluster': 'pixel_som_cluster',\n",
    "        'metacluster': 'pixel_meta_cluster',\n",
    "        'mc_name': 'pixel_meta_cluster_rename'\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# create the mapping from pixel SOM to pixel meta cluster\n",
    "pixel_remapped_dict = dict(\n",
    "    pixel_remapped_data[\n",
    "        ['pixel_som_cluster', 'pixel_meta_cluster']\n",
    "    ].values\n",
    ")\n",
    "\n",
    "# create the mapping from pixel meta cluster to renamed pixel meta cluster\n",
    "pixel_renamed_meta_dict = dict(\n",
    "    pixel_remapped_data[\n",
    "        ['pixel_meta_cluster', 'pixel_meta_cluster_rename']\n",
    "    ].drop_duplicates().values\n",
    ")\n",
    "\n",
    "# re-compute average channel expression for each pixel meta cluster\n",
    "# and the number of pixels per meta cluster, add renamed meta cluster column in\n",
    "print(\"Re-computing average channel expression across pixel meta clusters\")\n",
    "pixel_channel_avg_meta_cluster = som_utils.compute_pixel_cluster_channel_avg(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    'pixel_meta_cluster',\n",
    "    pixel_data_dir + '_remapped',\n",
    "    keep_count=True\n",
    ")\n",
    "pixel_channel_avg_meta_cluster['pixel_meta_cluster_rename'] = \\\n",
    "    pixel_channel_avg_meta_cluster['pixel_meta_cluster'].map(pixel_renamed_meta_dict)\n",
    "\n",
    "# re-save the pixel channel average meta cluster table\n",
    "pixel_channel_avg_meta_cluster.to_csv(meta_cluster_avg_path, index=False)\n",
    "\n",
    "# re-assign pixel meta cluster labels back to the pixel channel average som cluster table\n",
    "print(\"Re-assigning meta cluster column in pixel SOM cluster average channel expression table\")\n",
    "pixel_channel_avg_som_cluster = pd.read_csv(som_cluster_avg_path)\n",
    "\n",
    "pixel_channel_avg_som_cluster['pixel_meta_cluster'] = \\\n",
    "    pixel_channel_avg_som_cluster['pixel_som_cluster'].map(pixel_remapped_dict)\n",
    "\n",
    "pixel_channel_avg_som_cluster['pixel_meta_cluster_rename'] = \\\n",
    "    pixel_channel_avg_som_cluster['pixel_meta_cluster'].map(pixel_renamed_meta_dict)\n",
    "\n",
    "# re-save the pixel channel average som cluster table\n",
    "pixel_channel_avg_som_cluster.to_csv(som_cluster_avg_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the color scheme returned by the interactive reclustering process. This will be for visualizing the pixel cluster overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pixel_cmap_gen"
    ]
   },
   "outputs": [],
   "source": [
    "raw_cmap, _ = som_utils.generate_meta_cluster_colormap_dict(\n",
    "    pixel_mcd.output_mapping_filename,\n",
    "    pixel_mcg.im_cl.cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: pixel cluster overlay (pixel meta clusters only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "pixel_overlay_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# select fovs to display\n",
    "pixel_fovs = test_fovs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "pixel_mask_gen"
    ]
   },
   "outputs": [],
   "source": [
    "# define the path to the channel file\n",
    "if img_sub_folder is None:\n",
    "    chan_file = os.path.join(\n",
    "        fovs[0], io_utils.list_files(os.path.join(tiff_dir, fovs[0]), substrs=['.tif', '.tiff'])[0]\n",
    "    )\n",
    "else:\n",
    "    chan_file = os.path.join(\n",
    "        fovs[0], img_sub_folder, io_utils.list_files(os.path.join(tiff_dir, fovs[0], img_sub_folder), substrs=['.tif', '.tiff'])[0]\n",
    "    )\n",
    "\n",
    "# generate the pixel cluster masks for each fov in pixel_fovs\n",
    "pixel_cluster_masks = data_utils.generate_pixel_cluster_mask(\n",
    "    pixel_fovs,\n",
    "    base_dir,\n",
    "    tiff_dir,\n",
    "    chan_file=chan_file,\n",
    "    pixel_data_dir=pixel_data_dir + '_remapped',\n",
    "    pixel_cluster_col='pixel_meta_cluster'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `save_pixel_masks`: replace with `True` if you want to save, files will be written as `{fov_name}_pixel_mask.tiff` in `pixel_output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "pixel_mask_save"
    ]
   },
   "outputs": [],
   "source": [
    "save_pixel_masks = True\n",
    "\n",
    "if save_pixel_masks:\n",
    "    data_utils.save_fov_images(\n",
    "        pixel_fovs,\n",
    "        os.path.join(base_dir, pixel_output_dir),\n",
    "        pixel_cluster_masks,\n",
    "        sub_dir='pixel_masks',\n",
    "        name_suffix='_pixel_mask'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mantis creation\n",
    "create_mantis_project(mantis_project_path=os.path.join(base_dir, pixel_output_dir, 'mantis'),\n",
    "                      img_data_path=tiff_dir,\n",
    "                      mask_output_dir=os.path.join(base_dir, pixel_output_dir, 'pixel_masks'),\n",
    "                      mask_suffix='_pixel_mask',\n",
    "                      mapping_path = os.path.join(base_dir, pixel_output_dir, pixel_cluster_prefix + '_pixel_meta_cluster_mapping.csv'),\n",
    "                     seg_dir=segmentation_dir, img_sub_folder='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TONIC_TMA23_R6C1_pixel_mask.tiff',\n",
       " 'TONIC_TMA15_R11C2_pixel_mask.tiff',\n",
       " 'TONIC_TMA23_R9C4_pixel_mask.tiff',\n",
       " 'TONIC_TMA6_R7C4_pixel_mask.tiff',\n",
       " 'TONIC_TMA23_R6C3_pixel_mask.tiff',\n",
       " 'TONIC_TMA18_R2C2_pixel_mask.tiff',\n",
       " 'TONIC_TMA19_R6C6_pixel_mask.tiff',\n",
       " 'TONIC_TMA18_R9C1_pixel_mask.tiff',\n",
       " 'TONIC_TMA4_R1C2_pixel_mask.tiff',\n",
       " 'TONIC_TMA23_R1C2_pixel_mask.tiff']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io_utils.list_files(os.path.join(base_dir, pixel_output_dir, 'pixel_masks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "pixel_overlay_gen"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a88e3e9dc341a4b922ff95c1a3ba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc80429c1db475f9f462046cf96f710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_utils.plot_pixel_cell_cluster_overlay(\n",
    "    pixel_cluster_masks,\n",
    "    pixel_fovs,\n",
    "    os.path.join(base_dir, pixel_meta_cluster_remap_name),\n",
    "    metacluster_colors=raw_cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = io_utils.list_files(os.path.join(base_dir, pixel_output_dir, 'mantis/TONIC_TMA6_R5C2'), '.tiff')\n",
    "images = [image.split('.tiff')[0] for image in images]\n",
    "#images = [image for image in images if image not in channels]\n",
    "images = [image for image in images if image not in ['ECAD', 'CK17', 'FOXP3', 'CD11c', 'CD56', 'CD20', 'CD8', 'CD3','population_pixel_mask', 'cell_segmentation', 'H3K27me3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Au',\n",
       " 'CD14',\n",
       " 'CD163',\n",
       " 'CD31',\n",
       " 'CD38',\n",
       " 'CD4',\n",
       " 'CD45',\n",
       " 'CD45RB',\n",
       " 'CD45RO',\n",
       " 'CD57',\n",
       " 'CD68',\n",
       " 'CD69',\n",
       " 'Calprotectin',\n",
       " 'ChyTr',\n",
       " 'Collagen1',\n",
       " 'FAP',\n",
       " 'Fe',\n",
       " 'Fibronectin',\n",
       " 'GLUT1',\n",
       " 'H3K9ac',\n",
       " 'HLA1',\n",
       " 'HLADR',\n",
       " 'IDO',\n",
       " 'Ki67',\n",
       " 'LAG3',\n",
       " 'Noodle',\n",
       " 'PD1',\n",
       " 'PDL1',\n",
       " 'SMA',\n",
       " 'TBET',\n",
       " 'TCF1',\n",
       " 'TIM3',\n",
       " 'Vim',\n",
       " 'chan_115',\n",
       " 'chan_141',\n",
       " 'chan_39',\n",
       " 'chan_45',\n",
       " 'chan_48',\n",
       " 'ECAD_smoothed',\n",
       " 'CK17_smoothed',\n",
       " 'CD11c_nuc_exclude',\n",
       " 'FOXP3_nuc_include']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "folders = io_utils.list_folders(os.path.join(base_dir, pixel_output_dir, 'mantis'))\n",
    "for folder in folders:\n",
    "    for image in images:\n",
    "        os.remove(os.path.join(base_dir, pixel_output_dir, 'mantis', folder, image + '.tiff'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Save parameters for use in cell clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are saved:\n",
    "\n",
    "* `fovs`: the subset of fovs\n",
    "* `channels`: the subset of channels\n",
    "* `segmentation_dir`: the path to the directory containing your segmentated images per FOV (generated from `Segment_Image_Data.ipynb`)\n",
    "* `seg_suffix`: the suffix plus the file extension of the segmented images for each FOV\n",
    "* `pixel_data_dir`: the name of the directory containing tne full pixel data with the pixel SOM and consensus cluster assignments\n",
    "* `pc_chan_avg_som_cluster_name`: the name of the file containing the average channel expression per pixel SOM cluster\n",
    "* `pc_chan_avg_meta_cluster_name`: same as above except for pixel meta clusters\n",
    "\n",
    "The save file will be `{pixel_cluster_prefix}_cell_clustering_params.json` and will be placed in `pixel_output_dir`. Note that the `pixel_output_dir` you use in `example_pixel_clustering.ipynb` should be the same as in `example_cell_clustering.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "cell_param_save"
    ]
   },
   "outputs": [],
   "source": [
    "# define the params dict\n",
    "cell_clustering_params = {\n",
    "    'fovs': fovs,\n",
    "    'channels': channels,\n",
    "    'segmentation_dir': segmentation_dir,\n",
    "    'seg_suffix': seg_suffix,\n",
    "    'pixel_data_dir': pixel_data_dir,\n",
    "    'pc_chan_avg_som_cluster_name': pc_chan_avg_som_cluster_name,\n",
    "    'pc_chan_avg_meta_cluster_name': pc_chan_avg_meta_cluster_name\n",
    "}\n",
    "\n",
    "# save the params dict\n",
    "with open(os.path.join(base_dir, pixel_output_dir, '%s_cell_clustering_params.json' % pixel_cluster_prefix), 'w') as fh:\n",
    "    json.dump(cell_clustering_params, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def create_mantis_project(mantis_project_path, img_data_path, mask_output_dir, mask_suffix, mapping_path, \n",
    "                          seg_dir, img_sub_folder='normalized'):\n",
    "    \n",
    "    if not os.path.exists(mantis_project_path):\n",
    "        os.makedirs(mantis_project_path)\n",
    "        \n",
    "    # create key from cluster number to cluster name\n",
    "    map_df = pd.read_csv(mapping_path)\n",
    "    map_df = map_df.loc[:, ['metacluster', 'mc_name']]\n",
    "\n",
    "    # remove duplicates from df\n",
    "    map_df = map_df.drop_duplicates()\n",
    "    map_df = map_df.sort_values(by=['metacluster'])\n",
    "    \n",
    "    # rename for mantis names\n",
    "    map_df = map_df.rename({'metacluster': 'region_id', 'mn_name': 'region_name'}, axis=1)\n",
    "    \n",
    "    # get names of fovs with masks\n",
    "    mask_names = io_utils.list_files(mask_output_dir, mask_suffix)\n",
    "    fov_names = io_utils.extract_delimited_names(mask_names, delimiter=mask_suffix)\n",
    "    \n",
    "    # create a folder with image data, pixel masks, and segmentation mask\n",
    "    for idx, val in enumerate(fov_names):\n",
    "        \n",
    "        # set up paths\n",
    "        img_source_dir = os.path.join(img_data_path, val, img_sub_folder)\n",
    "        output_dir = os.path.join(mantis_project_path, val)\n",
    "        \n",
    "        # copy image data if not already copied in from previous round of clustering\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "            # copy all channels into new folder\n",
    "            chans = io_utils.list_files(img_source_dir, '.tiff')\n",
    "            for chan in chans:\n",
    "                shutil.copy(os.path.join(img_source_dir, chan), os.path.join(output_dir, chan))\n",
    "\n",
    "        # copy mask into new folder\n",
    "        mask_name = mask_names[idx]\n",
    "        shutil.copy(os.path.join(mask_output_dir, mask_name), os.path.join(output_dir, 'population{}.tiff'.format(mask_suffix)))\n",
    "        \n",
    "        # copy segmentations into directory\n",
    "        seg_name = val + '_feature_0.tif'\n",
    "        shutil.copy(os.path.join(seg_dir, seg_name), os.path.join(output_dir, 'cell_segmentation.tiff'))\n",
    "        \n",
    "        # copy mapping into directory\n",
    "        map_df.to_csv(os.path.join(output_dir, 'population{}.csv'.format(mask_suffix)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
